# Traitement d'Images avec Deep Learning (CNN)

## üìù Contexte du projet

La reconnaissance faciale est aujourd‚Äôhui au c≈ìur de nombreuses applications modernes : s√©curit√©, biom√©trie, r√©seaux sociaux, sant√©, ou encore commerce. Toutefois, reconna√Ætre un visage en conditions r√©elles reste un d√©fi majeur, en raison des variations d‚Äô√©clairage, de pose, d'expression, d'√¢ge ou encore de qualit√© d‚Äôimage.

Dans ce projet, nous explorons l‚Äôutilisation de techniques de **deep learning** pour aborder le probl√®me de la reconnaissance faciale √† partir du jeu de donn√©es **Labeled Faces in the Wild (LFW)**. Ce dataset, devenu un standard dans la recherche, propose plus de 13 000 images de visages collect√©es sur Internet, annot√©es avec les noms des personnes photographi√©es.

Les images ont √©t√© d√©tect√©es √† l‚Äôaide du d√©tecteur de visages de Viola-Jones, et pr√©sentent des conditions vari√©es et non contr√¥l√©es ‚Äî refl√©tant ainsi les difficult√©s d‚Äôune application en environnement r√©el. Le dataset comporte **1 680 personnes ayant au moins deux images diff√©rentes**, ce qui le rend particuli√®rement adapt√© √† l‚Äôentra√Ænement de mod√®les de reconnaissance √† l‚Äôaide de r√©seaux de neurones convolutifs (CNN).

Notre objectif est de :

- Pr√©traiter et organiser les images du dataset,
- Entra√Æner un mod√®le de classification (ou de v√©rification) de visages,
- √âvaluer ses performances sur un ensemble de test non vu,
- √âtudier les limites et axes d‚Äôam√©lioration du syst√®me.

---

## R√©sum√© des essais r√©alis√©s

<img width="1138" height="352" alt="image" src="https://github.com/user-attachments/assets/9a218f2f-c3f8-4f34-ab32-56c44f181769" />


### Premier test : CNN simple

- Mod√®le basique avec 2 couches convolutionnelles et 1 couche dense finale.  
- Images redimensionn√©es √† 64x64 pixels.  
- R√©sultat : **~15 % de pr√©cision** sur le test.  
- Limites : mod√®le trop simple, peu d‚Äôimages par classe, pas d‚Äôaugmentation des donn√©es, taille d‚Äôimage faible.
- 
<img width="1267" height="577" alt="image" src="https://github.com/user-attachments/assets/1e5b1ffa-45b1-4860-a30f-6aefabdfc95d" />

---

### Deuxi√®me test : CNN am√©lior√© + augmentation de donn√©es

- Ajout d‚Äôune couche convolutionnelle suppl√©mentaire et dropout pour √©viter le sur-apprentissage.  
- Augmentation de donn√©es (rotation, zoom, translation, flip).  
- Filtrage plus strict : personnes avec au moins 3 images conserv√©es.  
- R√©sultat : **~21 % de pr√©cision**.  
- Am√©lioration notable, mais encore insuffisant pour une reconnaissance fiable.

---

### Troisi√®me test : Transfert learning avec MobileNetV2 pr√©-entra√Æn√©

- Images redimensionn√©es √† 160x160 pixels (taille attendue par MobileNetV2).  
- Filtrage strict : minimum 15 images par personne pour un meilleur apprentissage.  
- Couches de MobileNetV2 gel√©es, ajout d‚Äôun classifieur personnalis√© avec dropout.  
- R√©sultat : **~54 % de pr√©cision**.

  <img width="1253" height="570" alt="image" src="https://github.com/user-attachments/assets/2f523081-b09e-4a65-9bf2-1749157fb1b0" />

- Conclusion : le transfert learning apporte un vrai gain de performance gr√¢ce √† l‚Äôutilisation de repr√©sentations visuelles pr√©-apprises.

---
Note sur les r√©sultats :
Ce quatrieme entra√Ænement √©tait un test visant √† analyser la stabilit√© du mod√®le. Les r√©sultats montrent une pr√©cision faible (< 17%) et des oscillations importantes dans la perte de validation, indiquant un apprentissage instable.
Des am√©liorations pr√©vues incluent la r√©duction du learning rate, l‚Äôutilisation d‚Äôoptimiseurs adapt√©s (AdamW), la mise en place de data augmentation, et l‚Äôoptimisation de l‚Äôarchitecture pour mieux s‚Äôadapter aux donn√©es.
<img width="1257" height="575" alt="image" src="https://github.com/user-attachments/assets/353a4c6f-4f3f-421f-8d99-bd3b7123f40f" />

üìù Interpr√©tation des r√©sultats
1. Accuracy (Pr√©cision)
Observation :

La pr√©cision d‚Äôentra√Ænement et de validation reste tr√®s basse (< 0.17).

La validation chute fortement entre les √©poques 2 et 5 avant de remonter.

Interpr√©tation :

Le mod√®le n‚Äôarrive pas √† apprendre des repr√©sentations utiles.

Les variations brusques de la pr√©cision de validation indiquent probablement un petit dataset ou un apprentissage instable.

2. Loss (Perte)
Observation :

La perte d‚Äôentra√Ænement diminue globalement, ce qui signifie que le mod√®le s‚Äôadapte au jeu d‚Äôentra√Ænement.

La perte de validation est instable : baisse ‚Üí remont√©e ‚Üí baisse √† nouveau.

Interpr√©tation :

Les oscillations peuvent indiquer un learning rate trop √©lev√© ou un bruit dans les donn√©es.

Le fait que la perte baisse sur les deux ensembles √† la fin sugg√®re que l‚Äôentra√Ænement n‚Äôest pas encore converg√©.



## Points cl√©s √† retenir

- **Qualit√© des donn√©es** : avoir suffisamment d‚Äôexemples par personne est crucial.  
- **Augmentation des donn√©es** : n√©cessaire pour am√©liorer la robustesse du mod√®le.  
- **Taille d‚Äôimage** : plus grande, plus d‚Äôinformations et meilleures performances.  
- **Transfert learning** : m√©thode efficace pour exploiter des mod√®les pr√©-entra√Æn√©s sur de larges bases et les adapter √† des t√¢ches sp√©cifiques.

---

*Merci de consulter le code pour plus de d√©tails sur les impl√©mentations et les param√®tres.*

