# Traitement d'Images avec Deep Learning (CNN)

## üìù Contexte du projet

La reconnaissance faciale est aujourd‚Äôhui au c≈ìur de nombreuses applications modernes : s√©curit√©, biom√©trie, r√©seaux sociaux, sant√©, ou encore commerce. Toutefois, reconna√Ætre un visage en conditions r√©elles reste un d√©fi majeur, en raison des variations d‚Äô√©clairage, de pose, d'expression, d'√¢ge ou encore de qualit√© d‚Äôimage.

Dans ce projet, nous explorons l‚Äôutilisation de techniques de **deep learning** pour aborder le probl√®me de la reconnaissance faciale √† partir du jeu de donn√©es **Labeled Faces in the Wild (LFW)**. Ce dataset, devenu un standard dans la recherche, propose plus de 13 000 images de visages collect√©es sur Internet, annot√©es avec les noms des personnes photographi√©es.

Les images ont √©t√© d√©tect√©es √† l‚Äôaide du d√©tecteur de visages de Viola-Jones, et pr√©sentent des conditions vari√©es et non contr√¥l√©es ‚Äî refl√©tant ainsi les difficult√©s d‚Äôune application en environnement r√©el. Le dataset comporte **1 680 personnes ayant au moins deux images diff√©rentes**, ce qui le rend particuli√®rement adapt√© √† l‚Äôentra√Ænement de mod√®les de reconnaissance √† l‚Äôaide de r√©seaux de neurones convolutifs (CNN).

Notre objectif est de :

- Pr√©traiter et organiser les images du dataset,
- Entra√Æner un mod√®le de classification (ou de v√©rification) de visages,
- √âvaluer ses performances sur un ensemble de test non vu,
- √âtudier les limites et axes d‚Äôam√©lioration du syst√®me.

---

## R√©sum√© des essais r√©alis√©s

### Premier test : CNN simple

- Mod√®le basique avec 2 couches convolutionnelles et 1 couche dense finale.  
- Images redimensionn√©es √† 64x64 pixels.  
- R√©sultat : **~15 % de pr√©cision** sur le test.  
- Limites : mod√®le trop simple, peu d‚Äôimages par classe, pas d‚Äôaugmentation des donn√©es, taille d‚Äôimage faible.

---

### Deuxi√®me test : CNN am√©lior√© + augmentation de donn√©es

- Ajout d‚Äôune couche convolutionnelle suppl√©mentaire et dropout pour √©viter le sur-apprentissage.  
- Augmentation de donn√©es (rotation, zoom, translation, flip).  
- Filtrage plus strict : personnes avec au moins 3 images conserv√©es.  
- R√©sultat : **~21 % de pr√©cision**.  
- Am√©lioration notable, mais encore insuffisant pour une reconnaissance fiable.

---

### Troisi√®me test : Transfert learning avec MobileNetV2 pr√©-entra√Æn√©

- Images redimensionn√©es √† 160x160 pixels (taille attendue par MobileNetV2).  
- Filtrage strict : minimum 15 images par personne pour un meilleur apprentissage.  
- Couches de MobileNetV2 gel√©es, ajout d‚Äôun classifieur personnalis√© avec dropout.  
- R√©sultat : **~54 % de pr√©cision**.  
- Conclusion : le transfert learning apporte un vrai gain de performance gr√¢ce √† l‚Äôutilisation de repr√©sentations visuelles pr√©-apprises.

---

## Points cl√©s √† retenir

- **Qualit√© des donn√©es** : avoir suffisamment d‚Äôexemples par personne est crucial.  
- **Augmentation des donn√©es** : n√©cessaire pour am√©liorer la robustesse du mod√®le.  
- **Taille d‚Äôimage** : plus grande, plus d‚Äôinformations et meilleures performances.  
- **Transfert learning** : m√©thode efficace pour exploiter des mod√®les pr√©-entra√Æn√©s sur de larges bases et les adapter √† des t√¢ches sp√©cifiques.

---

*Merci de consulter le code pour plus de d√©tails sur les impl√©mentations et les param√®tres.*

